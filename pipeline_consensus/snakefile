
# snakemake --profile configs/slurm2 --batch run_main=1/1 
# snakemake --profile configs/slurm2 all
# snakemake --profile configs/slurm all



import os
from datetime import datetime
import time
import re
from shutil import copyfile

import pandas as pd
import re

configfile: "config.json"

reference = config["reference"]
bed_file = config["bed_file"]
out_dir = config["out_dir"]
samples_path = config["samples_path"]
batch_path = config["batch_paths"]["201123"]

#print(batch_path)

df = pd.read_table(samples_path, sep="\t")



df["forward"] = batch_path + df["forward"]
df["reverse"] = batch_path + df["reverse"]


print(df)

print("---")

# _ is a dataframe with one line per sample, so that many sample_libraries can be merged together.
_ = df.groupby("sample").sum() # So you can merge more runs from the same isolate?
lib_delim = config["library_delimiter"]

print(_)


# Somehow format the sample_library column by some delimiter and join it with underscores.
#_["sample_library"] = _["sample_library"].apply(lambda x: str(x).split(lib_delim)[0] +"_" + "_".join(re.findall("L[0-9]+", x)))




rule all:
    input:
        expand("{out_dir}/consensus_sequences/{sample}.fa", out_dir = out_dir, sample = _["sample_library"])

rule call_consensus:
    input:
        "{out_dir}/trimmed_bams/{sample}.trimmed.sorted.bam"
    output:
        "{out_dir}/consensus_sequences/{sample}.fa"
    conda:
        "envs/ivar-inpipe.yml"
    shell:
        """
        samtools mpileup -A -Q 0 -d 0 {input} | ivar consensus -p {output} -m 10 -n N
        """

rule trim_reads:
    input:
        "{out_dir}/merged_aligned_bams/{sample}.sorted.bam"
    output:
        "{out_dir}/trimmed_bams/{sample}.trimmed.sorted.bam"
    params:
        bed="{bed}".format(bed = bed_file),
        tmp="{out_dir}/trimmed_bams/{sample}.trimmed.bam"
    conda:
        "envs/ivar-inpipe.yml"
    shell:
        """
        ivar trim -e -i {input} -b {params.bed} -p {params.tmp}
        samtools sort -T {wildcards.sample}.trim -o {output} {params.tmp}
        rm {params.tmp}
        """

rule merge_multiple_libraries:
    input:
        bams=lambda wildcards: df[df["sample"] == _[_["sample_library"] == wildcards.sample].index.values[0]]["sample_library"].apply(lambda x: os.path.join(out_dir, "aligned_bams", x +".sorted.bam")).tolist(),
        forward_=lambda wildcards: df[df["sample"] == _[_["sample_library"] == wildcards.sample].index.values[0]]["forward"].sort_values().tolist(),
        reverse_=lambda wildcards: df[df["sample"] == _[_["sample_library"] == wildcards.sample].index.values[0]]["reverse"].sort_values().tolist()
    output:
        bam="{out_dir}/merged_aligned_bams/{sample}.sorted.bam",
        fastq=expand("{{out_dir}}/merged_fastq/{{sample}}_R{readno}.fastq.gz", readno=[1,2])
    params:
        tmp="{out_dir}/merged_aligned_bams/{sample}.bam"
    conda:
        "envs/ivar-inpipe.yml"
    shell:
        """
        samtools merge {params.tmp} {input.bams}

        
        >&2 echo "is it here?"


        
        samtools sort -T {wildcards.sample}.merge -o {output.bam} {params.tmp}
        rm {params.tmp}
        cat {input.forward_} > {output.fastq[0]}
        cat {input.reverse_} > {output.fastq[1]}
        """

rule align_reads:
    input:
        lambda wildcards: df[df["sample_library"]==wildcards.sample][["forward", "reverse"]].values[0].tolist()
    output:
        temp("{out_dir}/aligned_bams/{sample}.sorted.bam")
    params:
        ref= "{ref}".format(ref = reference),
        tmp="{out_dir}/aligned_bams/{sample}.sorted.tmp.bam"
    conda:
        "envs/ivar-inpipe.yml"
    shell:
        """
    

        mkdir -p {out_dir}

        bwa mem {params.ref} {input[0]} {input[1]} | samtools view -F 4 -Sb | samtools sort -T {wildcards.sample}.align -o {params.tmp}


        samtools addreplacerg -r "ID:{wildcards.sample}" -o {output} {params.tmp}
        rm {params.tmp}
        """
